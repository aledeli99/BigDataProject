#Importing libraries and data

# Exploratory data analysis and plotting libraries
from google.colab import files
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from scipy.io import arff
import warnings
warnings.simplefilter("ignore")
# Models from Scikit-Learn
from sklearn import linear_model
from sklearn.linear_model import LogisticRegression
!pip install scikeras
# Deep Learning
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from scikeras.wrappers import KerasClassifier
from keras import regularizers
from sklearn.base import BaseEstimator, ClassifierMixin
from keras.callbacks import EarlyStopping
# Model evaluations
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, average_precision_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import preprocessing
from sklearn.preprocessing import scale
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

uploaded = files.upload()

df = pd.read_csv('Maternal Health Risk Data Set.csv')
print(df)

#Exploratory data analysis

df.info()

df.isna().sum()

Non ci sono valori mancanti.

risk_levels = df["RiskLevel"].value_counts()
print(risk_levels)

risk_levels_df = pd.DataFrame({"RiskLevel": risk_levels.index, "Count": risk_levels.values})

# Plotting risk level counts
palette = "Accent"
plt.figure(figsize=(10, 4))
ax = sns.barplot(data=risk_levels_df, x="RiskLevel", y="Count", palette=palette)
for container in ax.containers:
    ax.bar_label(container)
plt.title("Risk Level Count")
plt.show()

# Plotting risk level rates
plt.figure(figsize=(10, 4))
plt.pie(x=risk_levels, explode=[0.1, 0.1, 0.1], labels=risk_levels.index,
        colors=plt.get_cmap(palette)(range(len(risk_levels))), autopct="%.1f%%", shadow=True)
plt.title("Risk Levels Rate")
plt.show()

C'è uno sbilanciamento tra i livelli di rischio. In presenza di una forte rappresentanza di una classe rispetto alle altre, il modello potrebbe avere difficoltà a generalizzare bene e a ottenere prestazioni accurate per le classi meno rappresentate. Questo può portare a problemi come il sovra-addestramento sulla classe maggioritaria e la mancata identificazione accurata delle istanze delle classi minoritarie.


df.describe().T

Si notano valori anomali nel dataset, in particolare:
* Nella variabile "Età" sono presenti valori non coerenti con l'età fertile (es. 10, 70).
* Nella variabile "Frequenza cardiaca" il minimo è 7, un valore anomalo.  

plt.subplots(1, 2, figsize = (10, 4))
plt.subplot(121)
df.Age.plot.hist(color = "#7FC97F")
plt.title("Age Frequency");

plt.subplot(122)
df.HeartRate.plot.hist(color = "#F0027F")
plt.title("HeartRate Frequency");

* Il valore "7" della "Frequenza cardiaca" è un outlier, probabilmente un errore di inserimento.
* La variabile "Età" resta da approfondire.

px.box(df.Age, orientation = "h", points = "all")

Il valore "70" può essere considerato un outlier,  mentre il range "10-14" è discutibile.

https://aidos.it/wp-content/uploads/2013/10/UNFPA2013-completo-def.pdf

plt.figure(figsize = (20, 15))
for i, col in enumerate(df.iloc[:, 0:6]):
    plt.subplot(3, 3, i + 1)
    sns.boxplot(data = df.iloc[:, 0:6], x = col, color = "#F0027F")
    plt.xlabel(col, fontsize = 15)
    plt.xticks(fontsize = 10)

La distribuzione generale dell'età sul set di dati è compresa tra 20 e 40 anni. La pressione sistolica è compresa tra 100 e 120 mmHg, la pressione diastolica tra 60 e 90 mmHg, il livello glicemico nel sangue tra 7 e 8 mmol/l, la frequenza cardiaca tra 70 e 80 bpm e la temperatura corporea è per lo più di 98 F (36,6°).

sns.pairplot(df.iloc[:,:], hue = "RiskLevel");

Analisi bivariata. La matrice è simmetrica.

columns = df.columns[:len(df.columns) - 1]
for i in range(len(columns)):
    plt.figure(figsize = (8, 5))
    sns.catplot(data = df,
                x = "RiskLevel",
                y = columns[i],
                kind = "box",
                palette = ["#FDC086","#7FC97F","#FFFF99"]).set(title = f"Risk Levels by {columns[i]}");

Relazione lineare crescente tra i valori e i livelli di rischio, tranne per la temperatura corporea; la frequenza cardiaca sembra essere determinante per valori oltre una certa soglia.

# "low risk": 0,
# "mid risk": 1,
# "high risk": 2
risk_map = {"low risk": 0, "mid risk": 1, "high risk": 2}
df["RiskLevel"] = df["RiskLevel"].map(risk_map)
df

corr_matrix = df.corr()
fig, ax = plt.subplots(figsize = (15, 10))
ax = sns.heatmap(corr_matrix,
                 annot = True,
                 linewidths = 0.5,
                 fmt = ".2f",
                 cmap = "Greens");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)

La matrice di correlazione dice che DiastolicBP e SystolicBP sono altamente correlati tra loro. I valori della pressione sanguigna e della glicemia sono correlati all'età. Anche il livello di rischio dipende principalmente dalla glicemia, poi dai valori della pressione sanguigna e dall'età. La frequenza cardiaca, la temperatura corporea e l'età sono caratteristiche meno efficaci a livello di rischio qui.



#Data preprocessing

# Modify outliers heart rate
df['HeartRate'] = df['HeartRate'].replace(7, 70)

plt.subplot(122)
df.HeartRate.plot.hist(color = "#F0027F")
plt.title("HeartRate Frequency");

# Modify outliers age
df = df[~((df["Age"] == 70))]

plt.subplot(121)
df.Age.plot.hist(color = "#7FC97F")
plt.title("Age Frequency");



# Split data into features and target
X = df.drop(["RiskLevel"], axis = 1)
y = df["RiskLevel"]

X

y

#Modelling

##Logistic Regression Classifier

"""
Dividiamo il dataset in 3 parti:
- Set di addestramento (X_train, y_train),
- Set di Cross-Validation (X_cv, y_cv)
- Set di test (X_test, y_test).
Il 60% del dataset sarà utilizzato come set di training, il 20% come set di CV e il restante 20% come test set.

"""
X_train, x_, y_train, y_ = train_test_split(X, y, test_size=0.40, random_state=1)
X_cv, X_test, y_cv, y_test = train_test_split(x_, y_, test_size=0.50, random_state=1)

# Delete temporary variables
del x_, y_

print(f"the shape of the training set (input) is: {X_train.shape}")
print(f"the shape of the training set (target) is: {y_train.shape}\n")
print(f"the shape of the cross validation set (input) is: {X_cv.shape}")
print(f"the shape of the cross validation set (target) is: {y_cv.shape}\n")
print(f"the shape of the test set (input) is: {X_test.shape}")
print(f"the shape of the test set (target) is: {y_test.shape}")

# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_cvStandart = scaler.transform(X_cv)
X_testStandart = scaler.transform(X_test)

# Baseline LR with Scikit
logistic_regression = linear_model.LogisticRegression()
logistic_regression.fit(X_trainStandart, y_train)
pred_logistic_regression = logistic_regression.predict(X_testStandart)
print("Prediction on training set:", pred_logistic_regression)
print(f"Accuracy on test set: {round(logistic_regression.score(X_testStandart, y_test), 3)}")

"""
Utilizziamo la GridSearch per la ricerca degli iperparametri del modello di Regressione Logistica,
definendo i range di valori da testare.

"""
params_LR = {"tol": [0.0001,0.0002,0.0003],
            "C": [0.01, 0.1, 1, 10, 100],
            "penalty": ['l1', 'l2'],
            "intercept_scaling": [1, 2, 3, 4],
            "solver": ["liblinear", "lbfgs", "newton-cg"],
            "max_iter": [100, 200, 300],
              }


I parametri per la ricerca degli iperparametri sono i seguenti:

* "tol": Tolleranza per la convergenza. Valori più piccoli indicano una maggiore precisione, ma possono richiedere più tempo per convergere.
* "C": Inverso della forza di regolarizzazione. Valori più piccoli indicano una maggiore regolarizzazione (previene l'overfitting).
* "intercept_scaling": Scala per la penalizzazione dell'intercetta. Può influire sulla convergenza del modello.
* "solver": Algoritmo da utilizzare nel problema di ottimizzazione. I valori possibili includono "liblinear", "lbfgs", e "newton-cg".
* "max_iter": Numero massimo di iterazioni per la convergenza.

# GridSearchCV initialization
GridSearchCV_LR = GridSearchCV(estimator=linear_model.LogisticRegression(),
                                param_grid=params_LR,
                                cv=3,
                                scoring = "accuracy")
# Fit model with train data
GridSearchCV_LR.fit(X_trainStandart, y_train);

# Best model
best_model_LR = GridSearchCV_LR.best_estimator_

print(f"Best estimator for LR model:\n{GridSearchCV_LR.best_estimator_}")
print(f"Best parameter values for LR model:\n{GridSearchCV_LR.best_params_}")
print(f"Best score for LR model: {round(GridSearchCV_LR.best_score_, 3)}")

# Predictions
train_pred_LR = best_model_LR.predict(X_trainStandart)
cv_pred_LR = best_model_LR.predict(X_cvStandart)
test_pred_LR = best_model_LR.predict(X_testStandart)

# Calculate accuracy for each set
train_acc_LR = accuracy_score(y_train, train_pred_LR)
cv_acc_LR = accuracy_score(y_cv, cv_pred_LR)
test_acc_LR = accuracy_score(y_test, test_pred_LR)

# Print the results
print(f"Best Model: {best_model_LR}")
print(f"Training Set Accuracy: {train_acc_LR:.4f}")
print(f"CV Set Accuracy: {cv_acc_LR:.4f}")
print(f"Test Set Accuracy: {test_acc_LR:.4f}")

# Print Classification Report & Confusion Matrix
print("Classification Report")
print(classification_report(y_test, test_pred_LR))
print("Confusion Matrix:")
print(confusion_matrix(y_test, test_pred_LR))

ax= plt.subplot()
lr_cm = confusion_matrix(y_test, test_pred_LR)
sns.heatmap(lr_cm, annot=True, ax=ax, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels");
ax.set_ylabel("True Risk Levels");
ax.set_title("Confusion Matrix");
ax.xaxis.set_ticklabels(["Low", "Mid", "High"]);
ax.yaxis.set_ticklabels(["Low", "Mid", "High"]);

##Deep Learning Tensorflow 2l



"""
Dividiamo il dataset in due parti:
- Set di addestramento (X_train, y_train),
- Set di test (X_test, y_test).
Il 20% del dataset sarà utilizzato come set di test per renderlo confrontabile con il test set
della Regressione Logistica, mentre il restante 80% sarà usato come set di addestramento.

"""
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

"""
Creiamo un modello di rete neurale utilizzando Keras e Tensorflow per poi utilizzare
la GridSearchCV per trovare i migliori iperparametri per questo modello.
L'architettura del modello include strati nascosti seguiti da uno strato di dropout per ridurre l'overfitting.

"""
# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1 = [20,50,100])
# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[20,50,100], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs = 400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
"""
Si effettuano previsioni utilizzando il modello migliore sui dati standardizzati.
Come output otteniamo i logits delle previsioni, un range di valori non probabilistici;
successivamente elaboriamo attraverso la Softmax i risultati convertendo i valori
in una distribuzione di probabilità.

"""

dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

##Deep Learning Tensorflow 2l



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1 = [35,50,65])
# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[35,50,65], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs = 400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

##Deep Learning Tensorflow 4l

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1,neurons_2, neurons_3, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_2, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_3, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1=[70, 85, 100],
             neurons_2=[25, 45, 65],
             neurons_3=[10, 15, 20])

# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[70, 85, 100], neurons_2=[25, 45, 65], neurons_3=[10, 15, 20], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs=400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
"""
Si effettuano previsioni utilizzando il modello migliore sui dati standardizzati.
Come output otteniamo i logits delle previsioni, un range di valori non probabilistici;
successivamente elaboriamo attraverso la Softmax i risultati convertendo i valori
in una distribuzione di probabilità.

"""

dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

##Deep Learning Tensorflow 3l

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1, neurons_2, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_2, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1=[45, 65, 75],
             neurons_2=[15, 25, 35])
# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[45, 65, 75], neurons_2=[15, 25, 35], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs=400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

#Models comparison

# Comparison Neural Networks
model_names = ['Model 2l', 'Model 3l', 'Model 4l']
train_accuracies = [0.8379,0.8789,0.8441]
test_accuracies = [0.8015,0.8511,0.8089]
train_losses = [0.3897,0.2618,0.3081]
test_losses = [0.5439,0.4389,0.4290]
num_layers = [2,3,4]
num_neurons = [65,"65-25","70-65-20"]

plt.figure(figsize=(12, 6))
plt.bar(np.arange(len(model_names)) - 0.3, train_accuracies, 0.2, label="Train Accuracy", color="#b5e3d8")
plt.bar(np.arange(len(model_names)) - 0.1, test_accuracies, 0.2, label="Test Accuracy", color="#125d63")
plt.bar(np.arange(len(model_names)) + 0.1, train_losses, 0.2, label="Train Loss", color="#ffa372")
plt.bar(np.arange(len(model_names)) + 0.3, test_losses, 0.2, label="Test Loss", color="#ff6b6b")
plt.xticks(np.arange(len(model_names)), model_names, rotation=45, ha="right")
plt.xlabel("Models")
plt.ylabel("Values")
plt.title("Comparison Accuracy and Loss for each model")
for i in range(len(model_names)):
    plt.text(i + 0.45, max(train_losses[i], test_losses[i]) + 0.01, f"{num_layers[i]} layers\n{num_neurons[i]} neurons", ha='right', va='baseline')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


# Creating comparison lists
metrics = ["Accuracy"]
model_names = ["LogisticRegression", "DeepLearning"]
acc_list = [test_acc_LR, dl_acc]
tr_acc_list = [train_acc_LR, dl_acc_tr]

plt.figure(figsize = (10, 5))

plt.bar(np.arange(len(model_names)) - 0.2,
        np.array(acc_list)*100, 0.4, label = "Model Accuracy", color = "#b5e3d8")
plt.bar(np.arange(len(model_names)) + 0.2,
        np.array(tr_acc_list)*100, 0.4, label = "Training Accuracy", color = "#125d63")
plt.xticks(np.arange(len(model_names)), model_names, rotation = 90)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy Comparison")
plt.yticks(np.arange(0, 105, 5))
plt.legend(bbox_to_anchor = (1, 1), loc = "best")
plt.show()

# Display of confusion matrix for each model
disp1 = ConfusionMatrixDisplay(confusion_matrix=lr_cm, display_labels=np.arange(0, 3))
disp2 = ConfusionMatrixDisplay(confusion_matrix=dl_cm, display_labels=np.arange(0, 3))

# Subplot
fig, axes = plt.subplots(1, 2, figsize=(15, 7))

# Plot confusion matrix for each model
axes[0].set_title(model_names[0])
disp1.plot(include_values=True, cmap="GnBu", ax=axes[0])

axes[1].set_title(model_names[1])
disp2.plot(include_values=True, cmap="GnBu", ax=axes[1])

fig.suptitle("Comparison Confusion Matrix", y=0.92)

plt.show()


Come si può vedere dalle matrici di confusione, la Logistic Regression prevede un livello di rischio basso più correttamente, mentre il Deep Learning quelli di rischio medio e alto. Poiché si tratta di un set di dati medici, le previsioni più importanti per noi sono di alto livello di rischio.

# Generate and Balance the Data

#Class Imbalance Ratio (CIR)
"""
Misuriamo il grado di squilibrio tra le classi della variabile target nel dataset.
Un CIR più grande indica un maggiore squilibrio tra le classi.

"""
class_counts = df["RiskLevel"].value_counts()
cir = class_counts.max() / class_counts.min()

print(f"Class Imbalance Ratio (CIR): {cir}")

Questo valore suggerisce che c'è un piccolo squilibrio tra le classi della variabile target nel dataset.

##Data generation

"""
Alimentiamo il dataset originario generando nuovi examples attraverso la funzione
di Bootstrapping. I nuovi dati sono generati selezionando casualmente campioni
dal dataset esistente con sostituzione, mantenendo le caratteristiche generali del
dataset originale. La funzione seleziona casualmente "num_samples" righe dal dataset
Vengono mantenute nel dataset solo le righe con RiskLevel [0, 1, 2].

"""
def bootstrap_sampling_with_limit(dataframe, num_samples):
    sampled_data = dataframe.sample(n=num_samples, replace=True)
    sampled_data = sampled_data[sampled_data['RiskLevel'].isin([0, 1, 2])]
    return sampled_data

numero_di_campioni = 1000

nuovi_dati = bootstrap_sampling_with_limit(df, numero_di_campioni)

df_concatenato = pd.concat([df, nuovi_dati], ignore_index=True)

print(df_concatenato)

## Data balancing

"""
Per il bilanciamento delle classi è stata utilizzata "SMOTE" (Synthetic Minority Over-sampling Technique),
una tecnica di sovracampionamento. Questa crea nuovi campioni sintetici della classe minoritaria basati
su relazioni lineari tra le istanze esistenti della classe stessa, calcolando
le differenze tra i vicini dei campioni e utilizzandole per crearne di nuovi sintetici.

"""
X = df_concatenato.drop('RiskLevel', axis=1)
y = df_concatenato['RiskLevel']

smote = SMOTE(random_state=20)
X_resampled, y_resampled = smote.fit_resample(X, y)

print(X_resampled)
print(y_resampled)

risk_levels = y_resampled.value_counts()
print(risk_levels)

risk_levels_df = pd.DataFrame({"RiskLevel": risk_levels.index, "Count": risk_levels.values})

# Plotting risk level counts
palette = "Accent"
plt.figure(figsize=(10, 4))
ax = sns.barplot(data=risk_levels_df, x="RiskLevel", y="Count", palette=palette)
for container in ax.containers:
    ax.bar_label(container)
plt.title("Risk Level Count")
plt.show()

# Plotting risk level rates
plt.figure(figsize=(10, 4))
plt.pie(x=risk_levels, explode=[0.1, 0.1, 0.1], labels=risk_levels.index,
        colors=plt.get_cmap(palette)(range(len(risk_levels))), autopct="%.1f%%", shadow=True)
plt.title("Risk Levels Rate")
plt.show()


#Modelling

##Logistic Regression Classifier

X_train, x_, y_train, y_ = train_test_split(X_resampled, y_resampled, test_size=0.40, random_state=1)
X_cv, X_test, y_cv, y_test = train_test_split(x_, y_, test_size=0.50, random_state=1)

# Delete temporary variables
del x_, y_

print(f"the shape of the training set (input) is: {X_train.shape}")
print(f"the shape of the training set (target) is: {y_train.shape}\n")
print(f"the shape of the cross validation set (input) is: {X_cv.shape}")
print(f"the shape of the cross validation set (target) is: {y_cv.shape}\n")
print(f"the shape of the test set (input) is: {X_test.shape}")
print(f"the shape of the test set (target) is: {y_test.shape}")

# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_cvStandart = scaler.transform(X_cv)
X_testStandart = scaler.transform(X_test)



# Baseline LR with Scikit
logistic_regression = linear_model.LogisticRegression()
logistic_regression.fit(X_trainStandart, y_train)
pred_logistic_regression = logistic_regression.predict(X_testStandart)
print("Prediction on training set:", pred_logistic_regression)
print(f"Accuracy on test set: {round(logistic_regression.score(X_testStandart, y_test), 3)}")

params_LR = {"tol": [0.0001,0.0002,0.0003],
            "C": [0.01, 0.1, 1, 10, 100],
            "penalty": ['l1', 'l2'],
            "intercept_scaling": [1, 2, 3, 4],
            "solver": ["liblinear", "lbfgs", "newton-cg"],
            "max_iter": [100, 200, 300],
              }

# GridSearchCV initialization
GridSearchCV_LR = GridSearchCV(estimator=linear_model.LogisticRegression(),
                                param_grid=params_LR,
                                cv=3,
                                scoring = "accuracy")
# Fit model with train data
GridSearchCV_LR.fit(X_trainStandart, y_train);

# Best model
best_model_LR = GridSearchCV_LR.best_estimator_

print(f"Best estimator for LR model:\n{GridSearchCV_LR.best_estimator_}")
print(f"Best parameter values for LR model:\n{GridSearchCV_LR.best_params_}")
print(f"Best score for LR model: {round(GridSearchCV_LR.best_score_, 3)}")

# Predictions
train_pred_LR = best_model_LR.predict(X_trainStandart)
cv_pred_LR = best_model_LR.predict(X_cvStandart)
test_pred_LR = best_model_LR.predict(X_testStandart)

# Calculate accuracy for each set
train_acc_LR = accuracy_score(y_train, train_pred_LR)
cv_acc_LR = accuracy_score(y_cv, cv_pred_LR)
test_acc_LR = accuracy_score(y_test, test_pred_LR)

# Print the results
print(f"Best Model: {best_model_LR}")
print(f"Training Set Accuracy: {train_acc_LR:.4f}")
print(f"CV Set Accuracy: {cv_acc_LR:.4f}")
print(f"Test Set Accuracy: {test_acc_LR:.4f}")

# Print Classification Report & Confusion Matrix
print("Classification Report")
print(classification_report(y_test, test_pred_LR))
print("Confusion Matrix:")
print(confusion_matrix(y_test, test_pred_LR))

ax= plt.subplot()
lr_cm = confusion_matrix(y_test, test_pred_LR)
sns.heatmap(lr_cm, annot=True, ax=ax, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels");
ax.set_ylabel("True Risk Levels");
ax.set_title("Confusion Matrix");
ax.xaxis.set_ticklabels(["Low", "Mid", "High"]);
ax.yaxis.set_ticklabels(["Low", "Mid", "High"]);

##Deep Learning Tensorflow 3l

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1, neurons_2, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_2, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1=[75, 95, 110],
             neurons_2=[35, 55, 75])
# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[75, 95, 110], neurons_2=[35, 55, 75], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs=400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

##Deep Learning Tensorflow 4l

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1,neurons_2, neurons_3, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_2, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_3, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1=[65, 75, 85],
             neurons_2=[35, 55, 75],
             neurons_3=[15, 25, 35])

# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[65, 75, 85], neurons_2=[35, 55, 75], neurons_3=[15, 25, 35], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs=400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
"""
Si effettuano previsioni utilizzando il modello migliore sui dati standardizzati.
Come output otteniamo i logits delle previsioni, un range di valori non probabilistici;
successivamente elaboriamo attraverso la Softmax i risultati convertendo i valori
in una distribuzione di probabilità.

"""

dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

##Deep Learning Tensorflow 3l

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=1)
# Standardization Z-score
scaler = preprocessing.StandardScaler()
X_trainStandart = scaler.fit_transform(X_train)
X_testStandart = scaler.transform(X_test)

# Create Model for GridSearchCV with Dense layers
def create_model(neurons_1, neurons_2, epochs=400, activation='relu'):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(units=neurons_1, input_shape=(X_trainStandart.shape[1],), activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=neurons_2, activation=activation))
    model.add(keras.layers.Dropout(rate=0.2))
    model.add(keras.layers.Dense(units=3, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True, mode='min')
    return model

params= dict(neurons_1=[45, 65, 75],
             neurons_2=[15, 25, 35])
# Creation of KerasClassifier wrapper for Scikit-learn
model = KerasClassifier(build_fn=create_model, neurons_1=[45, 65, 75], neurons_2=[15, 25, 35], epochs=400)
gs = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=3)
gs_results = gs.fit(X_trainStandart, y_train)
print(gs_results.best_score_, gs_results.best_params_)

# Model creation
best_model = gs_results.best_estimator_.model_
best_model.summary()

# Example of model training and history recovery
history = best_model.fit(X_trainStandart, y_train, validation_split=0.20, epochs=400, verbose=1)

# Plot of accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Plot of loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.rcParams['figure.dpi'] = 300
plt.show()

# Calculate accuracy for each set
dl_acc_tr = best_model.evaluate(X_trainStandart, y_train)[1]
print("Deep Learning Training Accuracy:", dl_acc_tr)
dl_acc = best_model.evaluate(X_testStandart, y_test)[1]
print("Deep Learning Model Accuracy:", dl_acc)

# Predictions as score
dl_pred_logits = best_model.predict(X_testStandart)
print(f"two example output vectors:\n {dl_pred_logits[:2]}")
print("largest value", np.max(dl_pred_logits), "smallest value", np.min(dl_pred_logits))

# Predictions as probability
dl_pred_prob = tf.nn.softmax(dl_pred_logits).numpy()
print(f"two example output vectors:\n {dl_pred_prob[:2]}")
print("largest value", np.max(dl_pred_prob), "smallest value", np.min(dl_pred_prob))

# The most likely class for each output vector
dl_pred = np.argmax(dl_pred_prob, axis=1)

# Classification Report & Confusion Matrix
print("Deep Learning Classification Report\n\n", classification_report(y_test, dl_pred))

dl_cm = confusion_matrix(y_test, dl_pred, labels=np.arange(0, 3))

# Plot
plt.figure(figsize=(8, 6))
ax = sns.heatmap(dl_cm, annot=True, cmap="GnBu", fmt='d')
ax.set_xlabel("Predicted Risk Levels")
ax.set_ylabel("True Risk Levels")
ax.set_title("Deep Learning Confusion Matrix")
ax.xaxis.set_ticklabels(["Low", "Mid", "High"])
ax.yaxis.set_ticklabels(["Low", "Mid", "High"])
plt.show()

#Models comparison

# Comparison Neural Networks
model_names = ['Model 3l', 'Model 3l', 'Model 4l']
train_accuracies = [0.8758,0.8925,0.8658]
test_accuracies = [0.8687,0.9021,0.8313]
train_losses = [0.2837,0.2304,0.2809]
test_losses = [0.3015,0.3269,0.4052]
num_layers = [3,3,4]
num_neurons = ["75-35","110-75","65-75-15"]

plt.figure(figsize=(12, 6))
plt.bar(np.arange(len(model_names)) - 0.3, train_accuracies, 0.2, label="Train Accuracy", color="#b5e3d8")
plt.bar(np.arange(len(model_names)) - 0.1, test_accuracies, 0.2, label="Test Accuracy", color="#125d63")
plt.bar(np.arange(len(model_names)) + 0.1, train_losses, 0.2, label="Train Loss", color="#ffa372")
plt.bar(np.arange(len(model_names)) + 0.3, test_losses, 0.2, label="Test Loss", color="#ff6b6b")
plt.xticks(np.arange(len(model_names)), model_names, rotation=45, ha="right")
plt.xlabel("Models")
plt.ylabel("Values")
plt.title("Comparison Accuracy and Loss for each model")
for i in range(len(model_names)):
    plt.text(i + 0.45, max(train_losses[i], test_losses[i]) + 0.01, f"{num_layers[i]} layers\n{num_neurons[i]} neurons", ha='right', va='baseline')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


# Creating comparison lists
metrics = ["Accuracy"]
model_names = ["LogisticRegression", "DeepLearning"]
acc_list = [test_acc_LR, dl_acc]
tr_acc_list = [train_acc_LR, dl_acc_tr]

plt.figure(figsize = (10, 5))

plt.bar(np.arange(len(model_names)) - 0.2,
        np.array(acc_list)*100, 0.4, label = "Model Accuracy", color = "#b5e3d8")
plt.bar(np.arange(len(model_names)) + 0.2,
        np.array(tr_acc_list)*100, 0.4, label = "Training Accuracy", color = "#125d63")
plt.xticks(np.arange(len(model_names)), model_names, rotation = 90)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy Comparison")
plt.yticks(np.arange(0, 105, 5))
plt.legend(bbox_to_anchor = (1, 1), loc = "best")
plt.show()

disp1 = ConfusionMatrixDisplay(confusion_matrix=lr_cm, display_labels=np.arange(0, 3))
disp2 = ConfusionMatrixDisplay(confusion_matrix=dl_cm, display_labels=np.arange(0, 3))
fig, axes = plt.subplots(1, 2, figsize=(15, 7))
axes[0].set_title(model_names[0])
disp1.plot(include_values=True, cmap="GnBu", ax=axes[0])
axes[1].set_title(model_names[1])
disp2.plot(include_values=True, cmap="GnBu", ax=axes[1])
fig.suptitle("Comparison Confusion Matrix", y=0.92)

plt.show()


Come si può vedere dalle matrici di confusione, la Logistic Regression prevede un livello di rischio basso più correttamente, mentre il Deep Learning quelli di rischio medio e alto. Poiché si tratta di un set di dati medici, le previsioni più importanti per noi sono di alto livello di rischio.
